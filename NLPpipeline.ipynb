{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPpipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwWWfYCYUgy4dfmRXvfudp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avi-000-Avi/NLP-pipeline-for-chatbots/blob/master/NLPpipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wgimDn4V1op",
        "colab_type": "code",
        "outputId": "90f34c62-8025-417a-b556-889b07fef9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8wtGmezXV4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\"\"\n",
        "Dealing with textual data is very crucial so to handle these text data we need some \n",
        "basic text processing steps. Most of the processing steps covered in this section are \n",
        "commonly used in NLP and involve the combination of several steps into a single \n",
        "executable flow. This is usually referred to as the NLP pipeline. These flow \n",
        "can be a combination of tokenization, stemming, word frequency, parts of \n",
        "speech tagging, etc.\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A8A3hVBXeRm",
        "colab_type": "code",
        "outputId": "12272de7-017d-4674-e098-1a769eed12f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentences = nltk.sent_tokenize(text)\n",
        "words = [nltk.word_tokenize(s) for s in sentences]\n",
        "words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Dealing',\n",
              "  'with',\n",
              "  'textual',\n",
              "  'data',\n",
              "  'is',\n",
              "  'very',\n",
              "  'crucial',\n",
              "  'so',\n",
              "  'to',\n",
              "  'handle',\n",
              "  'these',\n",
              "  'text',\n",
              "  'data',\n",
              "  'we',\n",
              "  'need',\n",
              "  'some',\n",
              "  'basic',\n",
              "  'text',\n",
              "  'processing',\n",
              "  'steps',\n",
              "  '.'],\n",
              " ['Most',\n",
              "  'of',\n",
              "  'the',\n",
              "  'processing',\n",
              "  'steps',\n",
              "  'covered',\n",
              "  'in',\n",
              "  'this',\n",
              "  'section',\n",
              "  'are',\n",
              "  'commonly',\n",
              "  'used',\n",
              "  'in',\n",
              "  'NLP',\n",
              "  'and',\n",
              "  'involve',\n",
              "  'the',\n",
              "  'combination',\n",
              "  'of',\n",
              "  'several',\n",
              "  'steps',\n",
              "  'into',\n",
              "  'a',\n",
              "  'single',\n",
              "  'executable',\n",
              "  'flow',\n",
              "  '.'],\n",
              " ['This',\n",
              "  'is',\n",
              "  'usually',\n",
              "  'referred',\n",
              "  'to',\n",
              "  'as',\n",
              "  'the',\n",
              "  'NLP',\n",
              "  'pipeline',\n",
              "  '.'],\n",
              " ['These',\n",
              "  'flow',\n",
              "  'can',\n",
              "  'be',\n",
              "  'a',\n",
              "  'combination',\n",
              "  'of',\n",
              "  'tokenization',\n",
              "  ',',\n",
              "  'stemming',\n",
              "  ',',\n",
              "  'word',\n",
              "  'frequency',\n",
              "  ',',\n",
              "  'parts',\n",
              "  'of',\n",
              "  'speech',\n",
              "  'tagging',\n",
              "  ',',\n",
              "  'etc',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WywwX7TLX8v9",
        "colab_type": "text"
      },
      "source": [
        "## Part-of-Speech tagging\n",
        "Some words have multiple meanings, for example, charge is a noun, but can also be a verb, (to) charge. Knowing a Part-of-Speech (POS) can help to disambiguate the meaning. Each token in a sentence has several attributes that we can use for our analysis.\n",
        "\n",
        "The POS of a word is one example: nouns are a person, place, or thing; verbs are actions or occurrences and adjectives are words that describe nouns. Using these attributes, it becomes straightforward to create a summary of a piece of text by counting the most common nouns, verbs, and adjectives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMhZLFObXosv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_wt = [nltk.pos_tag(w) for w in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA29gMRdYPXW",
        "colab_type": "code",
        "outputId": "d432591a-b2bc-443f-bf1b-27af98e7ef3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tagged_wt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Dealing', 'VBG'),\n",
              "  ('with', 'IN'),\n",
              "  ('textual', 'JJ'),\n",
              "  ('data', 'NNS'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('very', 'RB'),\n",
              "  ('crucial', 'JJ'),\n",
              "  ('so', 'RB'),\n",
              "  ('to', 'TO'),\n",
              "  ('handle', 'VB'),\n",
              "  ('these', 'DT'),\n",
              "  ('text', 'JJ'),\n",
              "  ('data', 'NN'),\n",
              "  ('we', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('some', 'DT'),\n",
              "  ('basic', 'JJ'),\n",
              "  ('text', 'NN'),\n",
              "  ('processing', 'NN'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('.', '.')],\n",
              " [('Most', 'JJS'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('processing', 'NN'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('covered', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('this', 'DT'),\n",
              "  ('section', 'NN'),\n",
              "  ('are', 'VBP'),\n",
              "  ('commonly', 'RB'),\n",
              "  ('used', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('NLP', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('involve', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('combination', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('several', 'JJ'),\n",
              "  ('steps', 'NNS'),\n",
              "  ('into', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('single', 'JJ'),\n",
              "  ('executable', 'JJ'),\n",
              "  ('flow', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('This', 'DT'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('usually', 'RB'),\n",
              "  ('referred', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('as', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('NLP', 'NNP'),\n",
              "  ('pipeline', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('These', 'DT'),\n",
              "  ('flow', 'NN'),\n",
              "  ('can', 'MD'),\n",
              "  ('be', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('combination', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('tokenization', 'NN'),\n",
              "  (',', ','),\n",
              "  ('stemming', 'VBG'),\n",
              "  (',', ','),\n",
              "  ('word', 'NN'),\n",
              "  ('frequency', 'NN'),\n",
              "  (',', ','),\n",
              "  ('parts', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('speech', 'NN'),\n",
              "  ('tagging', 'NN'),\n",
              "  (',', ','),\n",
              "  ('etc', 'FW'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqvTCbckYQfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patternPOS = []\n",
        "for tag in tagged_wt:\n",
        "  patternPOS.append([v for k,v in tag])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwWv9hL3Yf15",
        "colab_type": "code",
        "outputId": "710f2674-67fa-414f-921d-6cda501c8a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "patternPOS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['VBG',\n",
              "  'IN',\n",
              "  'JJ',\n",
              "  'NNS',\n",
              "  'VBZ',\n",
              "  'RB',\n",
              "  'JJ',\n",
              "  'RB',\n",
              "  'TO',\n",
              "  'VB',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'PRP',\n",
              "  'VBP',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'NN',\n",
              "  'NNS',\n",
              "  '.'],\n",
              " ['JJS',\n",
              "  'IN',\n",
              "  'DT',\n",
              "  'NN',\n",
              "  'NNS',\n",
              "  'VBN',\n",
              "  'IN',\n",
              "  'DT',\n",
              "  'NN',\n",
              "  'VBP',\n",
              "  'RB',\n",
              "  'VBN',\n",
              "  'IN',\n",
              "  'NNP',\n",
              "  'CC',\n",
              "  'VB',\n",
              "  'DT',\n",
              "  'NN',\n",
              "  'IN',\n",
              "  'JJ',\n",
              "  'NNS',\n",
              "  'IN',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  '.'],\n",
              " ['DT', 'VBZ', 'RB', 'VBN', 'TO', 'IN', 'DT', 'NNP', 'NN', '.'],\n",
              " ['DT',\n",
              "  'NN',\n",
              "  'MD',\n",
              "  'VB',\n",
              "  'DT',\n",
              "  'NN',\n",
              "  'IN',\n",
              "  'NN',\n",
              "  ',',\n",
              "  'VBG',\n",
              "  ',',\n",
              "  'NN',\n",
              "  'NN',\n",
              "  ',',\n",
              "  'NNS',\n",
              "  'IN',\n",
              "  'NN',\n",
              "  'NN',\n",
              "  ',',\n",
              "  'FW',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHxVaenod8-N",
        "colab_type": "text"
      },
      "source": [
        "## Extracting nouns\n",
        "Let's extract all of the nouns present in the corpus. This is very useful practice when you want to extract something specific. We are using NN, NNS, NNP, and NNPS tags to extract the nouns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnGkOMXBYhB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nouns = []\n",
        "for tag in tagged_wt:\n",
        "  nouns.append([k for k,v in tag if v in ['NN','NNS','NNP','NNPS']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFqrDAOjeEOr",
        "colab_type": "text"
      },
      "source": [
        "Extracting verbs\n",
        "Let's extract all of the verbs present in the corpus. In this case, we are using VB, VBD, VBG, VBN, VBP, and VBZ as verb tags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdCsNtgVY1bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "verbs = []\n",
        "for tag in tagged_wt:\n",
        "  verbs.append([v for k,v in tag if v in ['VB','VBD','VBG','VBN']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKseuRYiZXiH",
        "colab_type": "text"
      },
      "source": [
        "Now, let's use spacy to tokenize a piece of text and access the POS attribute for each token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTuo32beMtB",
        "colab_type": "text"
      },
      "source": [
        "As an example application, we'll tokenize the previous paragraph and count the most common nouns with the following code. We'll also lemmatize the tokens, which gives the root form a word, to help us standardize across forms of a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oPn51HQZPjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from tabulate import tabulate\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ZE5DuFaIwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(text)\n",
        "noun_counter = Counter(token.lemma_ for token in doc if token.pos_ == 'NOUN' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_PNEC32g9xa",
        "colab_type": "code",
        "outputId": "d91348cc-916f-4241-9f9b-0322bd4ea991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "doc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "Dealing with textual data is very crucial so to handle these text data we need some \n",
              "basic text processing steps. Most of the processing steps covered in this section are \n",
              "commonly used in NLP and involve the combination of several steps into a single \n",
              "executable flow. This is usually referred to as the NLP pipeline. These flow \n",
              "can be a combination of tokenization, stemming, word frequency, parts of \n",
              "speech tagging, etc."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMmhD-frb9Va",
        "colab_type": "code",
        "outputId": "f53c532f-b562-4a1b-a359-71819e252f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "noun_counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'combination': 2,\n",
              "         'datum': 2,\n",
              "         'flow': 2,\n",
              "         'frequency': 1,\n",
              "         'part': 1,\n",
              "         'pipeline': 1,\n",
              "         'processing': 2,\n",
              "         'section': 1,\n",
              "         'speech': 1,\n",
              "         'stemming': 1,\n",
              "         'step': 3,\n",
              "         'tagging': 1,\n",
              "         'text': 2,\n",
              "         'tokenization': 1,\n",
              "         'word': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TgMQKp3cA5K",
        "colab_type": "code",
        "outputId": "05a0de67-795e-42d3-f0bd-ce6ae2b46c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(tabulate(noun_counter.most_common(5), headers = ['Noun', 'Count']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noun           Count\n",
            "-----------  -------\n",
            "step               3\n",
            "datum              2\n",
            "text               2\n",
            "processing         2\n",
            "combination        2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkpaM64CdxRS",
        "colab_type": "text"
      },
      "source": [
        "## Dependency parsing\n",
        "Dependency parsing is a way to understand the relationships between words in a sentence. Dependency relations are a more fine-grained attribute, available to help build the model's understanding of the words through their relationships in a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GADXzytucT92",
        "colab_type": "code",
        "outputId": "516adaf6-a7e9-4aef-f346-ecff899b931c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc = nlp(sentences[2])\n",
        "doc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This is usually referred to as the NLP pipeline."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1nYR-KbjwUE",
        "colab_type": "code",
        "outputId": "b0a7a0d2-9258-446b-b1a9-1d56f79522c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "spacy.displacy.render(doc, style ='dep', options = {'distance':140}, jupyter = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2074994c883f487690abd1ff0214d321-0\" class=\"displacy\" width=\"1310\" height=\"347.0\" direction=\"ltr\" style=\"max-width: none; height: 347.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">usually</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">referred</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">as</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1030\">NLP</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1030\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"257.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">pipeline.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-0\" stroke-width=\"2px\" d=\"M70,212.0 C70,2.0 470.0,2.0 470.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,214.0 L62,202.0 78,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-1\" stroke-width=\"2px\" d=\"M210,212.0 C210,72.0 465.0,72.0 465.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M210,214.0 L202,202.0 218,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-2\" stroke-width=\"2px\" d=\"M350,212.0 C350,142.0 460.0,142.0 460.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M350,214.0 L342,202.0 358,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-3\" stroke-width=\"2px\" d=\"M490,212.0 C490,142.0 600.0,142.0 600.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M600.0,214.0 L608.0,202.0 592.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-4\" stroke-width=\"2px\" d=\"M490,212.0 C490,72.0 745.0,72.0 745.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,214.0 L753.0,202.0 737.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-5\" stroke-width=\"2px\" d=\"M910,212.0 C910,72.0 1165.0,72.0 1165.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910,214.0 L902,202.0 918,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-6\" stroke-width=\"2px\" d=\"M1050,212.0 C1050,142.0 1160.0,142.0 1160.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1050,214.0 L1042,202.0 1058,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-2074994c883f487690abd1ff0214d321-0-7\" stroke-width=\"2px\" d=\"M770,212.0 C770,2.0 1170.0,2.0 1170.0,212.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-2074994c883f487690abd1ff0214d321-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170.0,214.0 L1178.0,202.0 1162.0,202.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tvKbSfqdQac",
        "colab_type": "text"
      },
      "source": [
        "NER\n",
        "Finally, there's NER. Named entities are the proper nouns of sentences. Computers have gotten pretty good at figuring out if they're in a sentence and at classifying what type of entity they are. spacy handles NER at the document level, since the name of an entity can span several tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gk6YqDCc3qe",
        "colab_type": "code",
        "outputId": "f3a2cc68-8e3b-4567-ebd9-fa93052876fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "doc = nlp(u\"My name is Jack and I live in San Francisco.\")\n",
        "\n",
        "entity_types = ((ent.text, ent.label_) for ent in doc.ents)\n",
        "print(tabulate(entity_types, headers = ['Entity','Entity Type']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entity         Entity Type\n",
            "-------------  -------------\n",
            "Jack           PERSON\n",
            "San Francisco  GPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaoWH-PzdnFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}